{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "np.random.seed(42)\n",
    "lambda1 = np.random.normal(size=(c, c))\n",
    "lambda2 = np.random.normal(size=(c, c))\n",
    "lambda3 = np.random.normal(size=(c, c))\n",
    "G1 = np.random.normal(size=(c, c, c))\n",
    "G2 = np.random.normal(size=(c, c, c))\n",
    "U = np.random.normal(size=(c, c, c, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_naive(lambda1, lambda2, lambda3, G1, G2, U):\n",
    "    c = lambda1.shape[0]\n",
    "    Z = np.zeros(shape=(c, c, c, c))\n",
    "    for a, b, c, d, e, f, g, h, i, j in itertools.product(*([range(c)]*10)):\n",
    "        Z[a, h, i, j] += lambda1[a, b]*lambda2[d, e]*lambda3[g, h]*G1[c, b, d]*G2[f, e, g]*U[i, j, c, f]\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 ms ± 353 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Z = Z_naive(lambda1, lambda2, lambda3, G1, G2, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = Z_naive(lambda1, lambda2, lambda3, G1, G2, U)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "Using kernel: Python 3.11.5 locally\n",
    "\n",
    "Let's take a look at `einsum_path` output for our convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['einsum_path', (0, 3), (0, 2), (0, 3), (1, 2), (0, 1)]\n",
      "\n",
      "  Complete contraction:  ab,de,gh,cbd,feg,ijcf->ahij\n",
      "         Naive scaling:  10\n",
      "     Optimized scaling:  6\n",
      "      Naive FLOP count:  3.543e+05\n",
      "  Optimized FLOP count:  2.431e+03\n",
      "   Theoretical speedup:  145.740\n",
      "  Largest intermediate:  8.100e+01 elements\n",
      "--------------------------------------------------------------------------\n",
      "scaling                  current                                remaining\n",
      "--------------------------------------------------------------------------\n",
      "   4                 cbd,ab->acd                 de,gh,feg,ijcf,acd->ahij\n",
      "   4                 feg,de->dfg                    gh,ijcf,acd,dfg->ahij\n",
      "   4                 dfg,gh->dfh                       ijcf,acd,dfh->ahij\n",
      "   5               dfh,acd->acfh                          ijcf,acfh->ahij\n",
      "   6             acfh,ijcf->ahij                               ahij->ahij\n"
     ]
    }
   ],
   "source": [
    "path, repr = np.einsum_path(\"ab,de,gh,cbd,feg,ijcf\", lambda1, lambda2, lambda3, G1, G2, U, optimize=\"optimal\")\n",
    "print(f\"{path}\\n\\n{repr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the result, the minimal number of flops is $\\chi^6$ as opposed to $\\chi^{10}$ of the naive implementation.\n",
    "The function suggests the following sequence of convolutions:\n",
    "\n",
    "$Z_{ahij} = \\sum_{bcdefg}\\lambda^{(1)}{}_{ab}\\Gamma^{(1)}{}_{cbd}\\lambda^{(2)}{}_{de}\\Gamma^{(2)}{}_{feg}\\lambda^{(3)}{}_{gh}U_{ijcf} = $\n",
    "\n",
    "$= \\sum_{cdefg} T^{(1)}{}_{acd} \\lambda^{(2)}{}_{de}\\Gamma^{(2)}{}_{feg}\\lambda^{(3)}{}_{gh}U_{ijcf} = \n",
    "\\sum_{cdfg} T^{(1)}{}_{acd} T^{(2)}{}_{dfg} \\lambda^{(3)}{}_{gh}U_{ijcf} =$\n",
    "\n",
    "$= \\sum_{cdf} T^{(1)}{}_{acd} T^{(3)}{}_{dfh} U_{ijcf} = \\sum_{cf} T^{(4)}{}_{acfh} U_{ijcf}$.\n",
    "\n",
    "\n",
    "Let's write a function that mimicks the behaviour of `numpy.einsum` and calculates convolutions in the same fashion using only the primitive `numpy.tensordot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_optimal(lambda1, lambda2, lambda3, G1, G2, U):\n",
    "    args = [lambda1, lambda2, lambda3, G1, G2, U]\n",
    "    contraction_list = [((3, 0), {'b'}, 'cbd','ab', 'acd', [2, 0, 1]),\n",
    "                        ((2, 0), {'e'}, 'feg', 'de', 'dfg', [2, 0, 1]),\n",
    "                        ((3, 0), {'g'}, 'dfg', 'gh', 'dfh', [0, 1, 2]),\n",
    "                        ((2, 1), {'d'}, 'dfh', 'acd', 'acfh', [2, 3, 0, 1]),\n",
    "                        ((1, 0), {'c', 'f'}, 'acfh', 'ijcf', 'ahij', [0, 1, 2, 3])]\n",
    "    \n",
    "    for inds, idx_rm, input_left, input_right, results_index, permutations in contraction_list:\n",
    "        # inds - a tuple of two: list indices of the tensors that are contracted in the current iteration\n",
    "        # idx_rm - tensor indices that are being contracred\n",
    "        # input_left, input_right - tensor indices of the tensors being contracted\n",
    "        # results_index - tensor index of the resulting tensor\n",
    "        # permutations - list of permutations (as supplied to numpy.transpose) needed to\n",
    "        #   get desired index since after tensordot() the index of the resulting tensor\n",
    "        #   may not be the same as result_index.\n",
    "        arg_left = args.pop(inds[0])\n",
    "        arg_right = args.pop(inds[1])\n",
    "        tensor_result = (input_left + input_right)\n",
    "        for s in idx_rm:\n",
    "            tensor_result.replace(s, \"\")\n",
    "        left_pos, right_pos = [], []\n",
    "        for s in sorted(idx_rm):\n",
    "            left_pos.append(input_left.find(s))\n",
    "            right_pos.append(input_right.find(s))\n",
    "        new_view = np.tensordot(arg_left, arg_right, axes=(tuple(left_pos), tuple(right_pos)))\n",
    "        if results_index != tensor_result:\n",
    "            new_view = np.transpose(new_view, permutations)\n",
    "        args.append(new_view)\n",
    "    return args[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the implementation agains `Z_naive` and `numpy.einsum`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.803298653358641e-13\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Z = Z_naive(lambda1, lambda2, lambda3, G1, G2, U)\n",
    "Q = Z_optimal(lambda1, lambda2, lambda3, G1, G2, U)\n",
    "O = np.einsum(\"ab,de,gh,cbd,feg,ijcf\", lambda1, lambda2, lambda3, G1, G2, U, optimize=\"optimal\")\n",
    "print(np.linalg.norm(Z - Q))\n",
    "print(np.linalg.norm(O - Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's time the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.8 µs ± 562 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "Q = Z_optimal(lambda1, lambda2, lambda3, G1, G2, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903 µs ± 6.32 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "O = np.einsum(\"ab,de,gh,cbd,feg,ijcf\", lambda1, lambda2, lambda3, G1, G2, U, optimize=\"optimal\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
