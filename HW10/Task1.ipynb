{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from scipy.special import comb\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.array(list(map(lambda string: np.array(list(map(lambda x: 1 if x == 'H' else 0, string))),\n",
    "                                 ['HTTTHHTHTH', 'HHHHTHHHHH', 'HTHHHHHTHH', 'HTHTTTHHTT', 'THHHTHHHTH'])))\n",
    "\n",
    "hidden_parameters = np.array(list(product(*([[1, 0]]*(len(observations))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nhead = observations.sum(axis=1)\n",
    "Ntot = 10\n",
    "coefs = comb(Ntot, Nhead) / 2**Ntot\n",
    "\n",
    "def likelihood(p1: float, p2: float) -> float:\n",
    "    probas = np.array([p1, p2])\n",
    "    return sum([(coefs * np.power(probas[hidden], Nhead) * np.power(1.0 - probas[hidden], Ntot - Nhead)).prod()\n",
    "                for hidden in hidden_parameters])\n",
    "\n",
    "vlikelihood = np.vectorize(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "p1=0.5195682006547262, p2=0.7967582123327023\n"
     ]
    }
   ],
   "source": [
    "initial_simplex = ([[0.2, 0.9], [0.3, 0.6], [0.6, 0.9]])\n",
    "result = minimize(fun=lambda x: -vlikelihood(x[0], x[1]),\n",
    "                  method='Nelder-Mead',\n",
    "                  x0=[0.7, 0.4],\n",
    "                  options={'initial_simplex' : initial_simplex})\n",
    "p1, p2 = result['x']\n",
    "print(f'{result['message']}\\n{p1=}, {p2=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(p1, p2):\n",
    "    return np.log(vlikelihood(p1, p2))\n",
    "\n",
    "def p_inner(z: np.ndarray, p1: float, p2: float) -> np.ndarray:\n",
    "    probas = np.array([p1, p2])\n",
    "    return np.array([(coefs * np.power(probas[hidden], Nhead) * np.power(1.0 - probas[hidden], Ntot - Nhead)).prod()\n",
    "                     for hidden in hidden_parameters])\n",
    "\n",
    "def p_outer(p1: float, p2: float) -> float:\n",
    "    return np.sum(p_inner(hidden_parameters, p1, p2))\n",
    "\n",
    "def delta(theta: tuple[float, float], theta_n: tuple[float, float]) -> float:\n",
    "    return np.sum(np.multiply(p_inner(hidden_parameters, *theta_n),\n",
    "                              np.log(np.divide(p_inner(hidden_parameters, *theta),\n",
    "                                               np.multiply(p_inner(hidden_parameters, *theta_n),\n",
    "                                                           p_outer(*theta_n))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAlgorithm(object):\n",
    "    def __init__(self, tolerance: float, n_iter: int) -> None:\n",
    "        self.tolerance = tolerance\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def _estimate(self, observation: np.ndarray, guess: tuple[float, float]) -> np.ndarray:\n",
    "        p0, p1 = guess\n",
    "        n0, n1 = np.unique(observation, return_counts=True)[1]\n",
    "        prob = np.array([p0**n1 * (1 - p0)**n0,\n",
    "                         p1**n1 * (1 - p1)**n0])\n",
    "        return prob / np.sum(prob)\n",
    "    \n",
    "    def _find_coeff(self, observation: np.ndarray, probas: np.ndarray) -> list[float]:\n",
    "        n0, n1 = np.unique(observation, return_counts=True)[1]\n",
    "        return [n1 * probas[0], n0 * probas[0], n1 * probas[1], n0 * probas[1]]\n",
    "\n",
    "\n",
    "    def _find_next_guess(self, observations: np.ndarray, guess: tuple[float, float]) -> tuple[float, float]:\n",
    "        estimations = np.array([self._estimate(observation, guess) for observation in observations])\n",
    "        coeff = np.sum(np.array([self._find_coeff(observation, estimation)\n",
    "                                 for observation, estimation in zip(observations, estimations)]),\n",
    "                                 axis=0)\n",
    "        return (coeff[0]/(coeff[0]+coeff[1]),\n",
    "                coeff[2]/(coeff[2]+coeff[3]))\n",
    "    \n",
    "    def optimize(self, observations: np.ndarray, initial_guess: tuple[float, float]) -> tuple[float, float]:\n",
    "        guess = initial_guess\n",
    "        for _ in range(self.n_iter):\n",
    "            guess = self._find_next_guess(observations, guess)\n",
    "        return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1=0.5164223903331018, p2=0.7970029411867086\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = EMAlgorithm(1e-8, 2).optimize(observations, (0.5, 0.8))\n",
    "print(f'{p1=}, {p2=}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
